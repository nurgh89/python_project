{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Pandas\n",
    "\n",
    "# **Covered Topics**\n",
    "\n",
    "# - Initialization\n",
    "# - Column selection, addition, deletion\n",
    "# - Data Indexing & Selecting\n",
    "# - Handling Missing Value\n",
    "# - Combining Datasets\n",
    "# - Grouping and Sorting\n",
    "# - Pivot table\n",
    "# - Working with string\n",
    "# - Working with time series\n",
    "\n",
    "### Initialization\n",
    "### Import Library Pandas\n",
    "# Untuk dapat menginstall pandas, kamu bisa menjalankan perintah dengan menggunakan pip\n",
    "\n",
    "\n",
    "\n",
    "# pip install pandas\n",
    "\n",
    "\n",
    "\n",
    "#  pip install pandas\n",
    "# Jika sudah berhasil melakukan instalasi Pandas, kita dapat menggunakannya dengan cara import modul tersebut.\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Creating Dataframe\n",
    "# DataFrame adalah struktur data tabular yang disusun pada kolom dan baris berurut. Dataframe layaknya seperti 2-dimensi array, You can think of a data frame is like a table.\n",
    "\n",
    "# <img src=\"https://www.w3resource.com/w3r_images/pandas-data-structure.svg\">\n",
    "# Create dataframe using dictionary\n",
    "\n",
    "data_penjualan = {\n",
    "  \"product\": [\"product A\", \"product B\", \"product C\", \"product X\"],\n",
    "  \"hasil_penjualan\": [500000, 700000, 125000, 350000]\n",
    "}\n",
    "data_penjualan\n",
    "#load data into a DataFrame object:\n",
    "# df = pd.DataFrame(data_penjualan)\n",
    "\n",
    "# print(df)\n",
    "## Reading or loading the data from file\n",
    "\n",
    "# Untuk membaca data dari file berupa csv kita dapat melakukannya dengan command:\n",
    "\n",
    "pd.read_csv\n",
    "\n",
    "\n",
    "\n",
    "# download file from https://data.jakarta.go.id/dataset/data-penumpang-bus-sekolah-kpi\n",
    "# df.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "## Menulis pandas dataframe ke json file\n",
    "\n",
    "# gunakan `df.to_json` untuk menulis dataframe ke json file. format JSON disajikan dalam *key/value pair*\n",
    "\n",
    "# contoh:\n",
    "\n",
    "# `{\"key\":\"value\",\"key\":\"value\",\"key\":\"value\".}`\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "\n",
    "# Note:\n",
    "\n",
    "# *JSON (JavaScript Object Notation) adalah format file berbasis teks yang umumnya digunakan dalam proses pertukaran data antara server dan klien.*\n",
    "\n",
    "# baca json file ke dataframe menggunakan `pd.read_json`.\n",
    "\n",
    "# coba baca json file yang sudah di-export sebelumnya `./test_result.json`\n",
    "\n",
    "# ## cek sample data\n",
    "\n",
    "# `df.head()` dapat digunakan untuk melihat sample data row paling atas\n",
    "# # df.head()\n",
    "# # df.head(10)\n",
    "# Untuk menampilkan n record terakhir, dapat menggunakan perintah `tail(n)`. Jika tidak diberi parameter jumlah recordnya, maka secara default akan menampilkan 5 record\n",
    "# # df.tail()\n",
    "# Fungsi `sample()` pada Pandas dapat digunakan jika kita ingin menampilkan dataframe secara acak. Misalkan menampilkan 10 dataframe secara acak\n",
    "# # df.sample(10)\n",
    "# ## Informasi Struktur Data\n",
    "\n",
    "# Property shape dapat digunakan untuk mengetahui dimensi dari dataframe\n",
    "# # df.shape\n",
    "# Dari nilai property shape yang terlihat diatas, memberikan informasi bahwa DataFrame memiliki 31 baris/record dan 5 kolom.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Property DataFrame lainnya adalah `dtypes`, yang dapat digunakan untuk melihat struktur dari data\n",
    "\n",
    "# `df.dtypes`\n",
    "# # df.dtypes\n",
    "# Informasi lebih detail mengenai struktur DataFrame dapat dilihat menggunakan fungsi info()\n",
    "\n",
    "# `df.info()`\n",
    "# # df.info()\n",
    "# ## Informasi Statistik\n",
    "# Informasi statistik untuk setiap kolom seperti nilai minimum, nilai maksimum, standar deviasi, rata-rata dan sebagainya, dapat ditampilkan dengan mengikuti perintah berikut\n",
    "# # df.describe()\n",
    "# ## Column selection, addition, deletion\n",
    "# Untuk melihat list column gunakan `df.columns`\n",
    "# # df.columns\n",
    "# Kita dapat memilih kolom mana saja yang akan ditampilkan, yaitu dengan menyebutkan nama kolom yang akan ditampilkan.\n",
    "\n",
    "\n",
    "# Sebagai contoh kita hanya ingin menampilkan daerah_operasi\n",
    "\n",
    "# Contoh lain kita ingin menampilkan type_operasi, daerah_operasi, dan jumlah_penumpang\n",
    "\n",
    "# **adding column**\n",
    "\n",
    "# untuk menambahkan column, sama seperti dictionary, cukup definisikan column baru nya\n",
    "# # df[\"column baru\"] = \"New column\"\n",
    "# # df.head()\n",
    "# **deleting column**\n",
    "\n",
    "# untuk menghapus column, gunakan `df.drop`\n",
    "# df = df.drop(columns=[\"column baru\"])\n",
    "# df.head()\n",
    "## Data Indexing and Selection\n",
    "# Salah satu bagian penting yang digunakan dalam penyiapan data dan analisis data adalah filtering, yaitu pemilihan data dengan kriteria tertentu.\n",
    "# **Python loc() function**\n",
    "\n",
    "# *Example 1*\n",
    "\n",
    "# Bagi mereka yang terbiasa menggunakan SQL, ini adalah bagian dari pernyataan WHERE.\n",
    "\n",
    "# Misalnya, ingin menampilkan data untuk rute bus dengan jumlah bus >= 70\n",
    "\n",
    "# Misalnya, ingin menampilkan data untuk rute bus dengan jumlah bus >= 70, namun hanya column type_operasi dan daerah_operasi saja yang ditampilkan\n",
    "\n",
    "# Penggabungkan beberapa kondisi dapat menggunakan operator logika `AND(\"&\")` dan operator logika `OR(\"|\")` untuk memilih baris dengan lebih dari satu kriteria.\n",
    "\n",
    "# Misalnya kita ingin menampilkan data dengan jumlah bus > 70 dan jumlah penumpang > 20000\n",
    "\n",
    "# Penggunaan operator logika `AND (\"&\")` di atas, akan mengambil data yang cocok dengan kedua kriteria tersebut. Jika Anda ingin mendapatkan data yang cocok hanya untuk salah satu kriteria, dapat menggunakan operator logika `OR(\"|\")`\n",
    "# Fungsi `isin()` dapat digunakan untuk memfilter kolom jika nilainya ditentukan dalam bentuk list/daftar.\n",
    "\n",
    "# Untuk penyataan negasi atau NOT menggunakan tanda '~'\n",
    "\n",
    "# **Memfilter data menggunakan index**\n",
    "\n",
    "# Kita dapat menampilkan data berdasarkan index nya dengan menggunakan `loc` dan `iloc`\n",
    "# # df.loc[10:15]\n",
    "# # df.iloc[10:15]\n",
    "# ## Handling missing data\n",
    "\n",
    "# Perbedaan antara data yang ditemukan di banyak tutorial dan data di dunia nyata adalah bahwa data di dunia nyata jarang sekali bersih dan homogen. Lebih rumit lagi, sumber data yang berbeda mungkin menunjukkan data yang hilang dengan cara yang berbeda.\n",
    "\n",
    "# terdapat beberapa function yang dipakai untuk menghandle null values dalam Pandas data structures.\n",
    "\n",
    "\n",
    "# ```\n",
    "# isnull(): Generate a boolean mask indicating missing values\n",
    "# notnull(): Opposite of isnull()\n",
    "# dropna(): Return a filtered version of the data\n",
    "# fillna(): Return a copy of the data with missing values filled or imputed\n",
    "# ```\n",
    "\n",
    "\n",
    "### Detecting Null\n",
    "\n",
    "# Untuk mengecek data yang null atau tidak, gunakan `isnull() and notnull()`\n",
    "\n",
    "data_penjualan = {\n",
    "  \"product\": [\"product A\", \"product B\", \"product C\", \"product X\"],\n",
    "  \"hasil_penjualan\": [500000, None, 125000, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data_penjualan)\n",
    "\n",
    "print(df)\n",
    "# df.isnull()\n",
    "# df.notnull()\n",
    "### Dropping null values\n",
    "\n",
    "# terdapat function `dropna()` untuk menghapus null data dan fillna() untuk mengisi null value\n",
    "# df.dropna()\n",
    "# Sometimes rather than dropping NA values,\n",
    "# you'd rather replace them with a valid value.\n",
    "# This value might be a single number like zero,\n",
    "# or it might be some sort of imputation\n",
    "# or interpolation from the good values.\n",
    "\n",
    "# df.fillna(1000000)\n",
    "## Menggabungkan data\n",
    "### concat\n",
    "\n",
    "# `concat()` dapat digunakan pada data frame yang ditujukan untuk penggabungan.\n",
    "\n",
    "data_penjualan_1 = {\n",
    "  \"product\": [\"product A\", \"product B\", \"product C\", \"product X\"],\n",
    "  \"hasil_penjualan\": [500000, None, 125000, np.nan]\n",
    "}\n",
    "df_1 = pd.DataFrame(data_penjualan_1)\n",
    "df_1\n",
    "data_penjualan_2 = {\n",
    "  \"product\": [\"product Z\", \"product Y\", \"product V\", \"product W\"],\n",
    "  \"hasil_penjualan\": [500000, 750000, 125000, 1000000]\n",
    "}\n",
    "df_2 = pd.DataFrame(data_penjualan_2)\n",
    "df_2\n",
    "# pd.concat([df_1,df_2])\n",
    "# By default, the join is a union of the input columns (`join='outer'`), but we can change this to an intersection of the columns using `join='inner'`\n",
    "\n",
    "data_penjualan_1 = {\n",
    "  \"product\": [\"product A\", \"product B\", \"product C\", \"product X\"],\n",
    "  \"hasil_penjualan\": [500000, None, 125000, np.nan],\n",
    "  # \"company\": [\"company A\", \"company A\", \"company B\", \"company A\"]\n",
    "}\n",
    "df_1 = pd.DataFrame(data_penjualan_1)\n",
    "df_1\n",
    "data_penjualan_2 = {\n",
    "  \"product\": [\"product Z\", \"product Y\", \"product V\", \"product W\"],\n",
    "  \"hasil_penjualan\": [500000, 750000, 125000, 1000000],\n",
    "  # \"region\": [\"region A\", \"region C\", \"region B\", \"region A\"]\n",
    "}\n",
    "df_2 = pd.DataFrame(data_penjualan_2)\n",
    "df_2\n",
    "# pd.concat([df_1,df_2])\n",
    "# pd.concat([df_1,df_2], join='inner')\n",
    "### Merge\n",
    "\n",
    "# `merge()` digunakan untuk menggabungkan Series atau Data Frame yang bentuknya mirip dengan syntax join di SQL\n",
    "df_pelanggan = pd.DataFrame({'cust_id':[1, 2, 3, 4, 5],\n",
    "                          'nama':['nana','nini','nunu','nene','nono']})\n",
    "print(df_pelanggan)\n",
    "df_transaksi = pd.DataFrame({'transaksi_id': [3, 4, 8],\n",
    "                          'cust_id' : [1, 3, 5],\n",
    "                          'prod_id' : [8, 10, 11],\n",
    "                          'jumlah' : [3, 4, 2] })\n",
    "print(df_transaksi)\n",
    "df_product = pd.DataFrame({'product_id' : [8, 9, 10, 11, 12],\n",
    "                          'product_name' : ['Biskuit', 'Kopi', 'Gula', 'Beras', 'Minyak Goreng'],\n",
    "                       'harga' : [1000, 2000, 15000, 12000, 15000]})\n",
    "print(df_product)\n",
    "# Menggabungkan DataFrame dengan inner join\n",
    "# df1 = pd.merge(df_pelanggan,df_transaksi, on = 'cust_id', how='inner')\n",
    "# df1\n",
    "# Menggabungkan DataFrame dengan left join\n",
    "# df1 = pd.merge(df_pelanggan,df_transaksi, on = 'cust_id', how='left')\n",
    "# df1\n",
    "# Menggabungkan DataFrame dengan right join dengan key name yang berbeda\n",
    "# df1 = pd.merge(df_transaksi,df_product, left_on = 'prod_id', right_on = 'product_id', how='right')\n",
    "# df1\n",
    "# Join 3 DataFrame\n",
    "# new_df = pd.merge(df_pelanggan, df_transaksi, on = 'cust_id', how='inner')\n",
    "# final_df = pd.merge(new_df, df_product, left_on = 'prod_id', right_on = 'product_id', how='inner')\n",
    "# final_df\n",
    "## Grouping dan Aggregation\n",
    "\n",
    "# Pandas memiliki fungsi `groupby()` untuk melakukan perhitungan kelompok berdasarkan nilai unik sesuai kolom yang dipilih.\n",
    "# Menghitung rata-rata menggunakan `mean()`\n",
    "\n",
    "# Fungsi groupby() dapat digabungkan dengan fungsi agg().\n",
    "\n",
    "# Untuk melakukan bebrapa perhitungan statistik yang dikelompokkan berdasarkan nilai unik sebuah kolom, dapat dilakukan sebagai berikut\n",
    "# df.groupby('type_operasi').agg(\n",
    "#     avg_jumlah_penumpang=('jumlah_penumpang', 'mean'),\n",
    "#     sum_jumlah_penumpang=('jumlah_penumpang', 'sum'),\n",
    "#     max_jumlah_penumpang=('jumlah_penumpang', 'max')\n",
    "#     )\n",
    "# Perhitungan aggregasi untuk kolom yang berbeda\n",
    "# df.groupby('type_operasi').agg(\n",
    "#     avg_jumlah_penumpang=('jumlah_penumpang', 'mean'),\n",
    "#     sum_jumlah_bus=('jumlah_bus', 'sum'),\n",
    "#     max_jumlah_bus=('jumlah_bus', 'max')\n",
    "#     )\n",
    "# Supaya kolom grouping tidak ditampilkan sebagai index, maka parameter as_index diset False\n",
    "# df.groupby('type_operasi', as_index=False).agg(\n",
    "#     avg_jumlah_penumpang=('jumlah_penumpang', 'mean'),\n",
    "#     sum_jumlah_bus=('jumlah_bus', 'sum'),\n",
    "#     max_jumlah_bus=('jumlah_bus', 'max')\n",
    "#     )\n",
    "### Mengurutkan Data\n",
    "# Fungsi `sort_values()` digunakan untuk melakukan pengurutan data berdasarkan dengan kolom yang disebutkan mulai dari nilai terkecil.\n",
    "df.sort_values('jumlah_bus').head()\n",
    "# df.groupby('type_operasi', as_index=False).agg(\n",
    "#     avg_jumlah_penumpang=('jumlah_penumpang', 'mean'),\n",
    "#     sum_jumlah_bus=('jumlah_bus', 'sum'),\n",
    "#     max_jumlah_bus=('jumlah_bus', 'max')\n",
    "#     )\n",
    "# df.groupby('type_operasi').agg(\n",
    "#     avg_jumlah_penumpang=('jumlah_penumpang', 'mean'),\n",
    "#     sum_jumlah_bus=('jumlah_bus', 'sum'),\n",
    "#     max_jumlah_bus=('jumlah_bus', 'max')\n",
    "# ).sort_values('sum_jumlah_bus', ascending=True)\n",
    "# Jika ingin mengurutkan data dengan menggunakan lebih dari satu kolom maka perlu ditentukan daftar nama kolom\n",
    "# df.sort_values(['jumlah_bus', 'jumlah_penumpang']).head(10)\n",
    "# Setiap kolom juga dapat memiliki tipe pengurutannya masing-masing, misalkan jumlah_bus diurutkan secara DESC dan jumlah_penumpang secara ASC\n",
    "# df.sort_values(['jumlah_bus', 'jumlah_penumpang'], ascending=[0, 1]).head(10)\n",
    "## Working with string\n",
    "df_pelanggan = pd.DataFrame({'cust_id':[1, 2, 3, 4, 5],\n",
    "                          'nama':['Kak nana','Kak nini','mba nunu','mpo nene','mba nono']})\n",
    "print(df_pelanggan)\n",
    "df_pelanggan['nama'].str.lower()\n",
    "df_pelanggan['nama'].str.len()\n",
    "df_pelanggan['nama'].str.startswith('m')\n",
    "df_pelanggan['nama'].str.split()\n",
    "df_pelanggan['nama'].str.split().str.get(-1)\n",
    "# Mencari data dengan huruf awal kapital menggunakan regex\n",
    "\n",
    "# More info: https://regex101.com/\n",
    "df_pelanggan['nama'].str.findall(r'^[A-Z].*')\n",
    "## Working with time series\n",
    "df_sample = pd.DataFrame(\n",
    "    {'date_fmt1' :['4/1/20', '4/2/20', '4/3/20', '4/4/20', '4/5/20', '4/6/20', '4/7/20'],\n",
    "     'date_fmt2' :['20200401', '20200402', '20200403', '20200404', '20200405', '20200406', '20200407'],\n",
    "     'date_fmt3' :['Apr.01.2020', 'Apr.02.2020', 'Apr.03.2020', 'Apr.04.2020', 'Apr.05.2020', 'Apr.06.2020', 'Apr.07.2020'],\n",
    "     'value' :[103, 112, 134, 150, 164, 192, 204]\n",
    "    })\n",
    "\n",
    "df_sample\n",
    "df_sample.dtypes\n",
    "### Merubah format string ke tipe date\n",
    "\n",
    "# Panda memiliki fungsi to_datetime yang bisa digunakan untuk mengkonversi STRING menjadi tipe data DATETIME. Format pembacaan tanggal dapat disesuaikan dengan menggunakan parameter format.\n",
    "df_sample['date01'] = pd.to_datetime(df_sample['date_fmt1'], format='%m/%d/%y')\n",
    "df_sample\n",
    "df_sample['date02'] = pd.to_datetime(df_sample.date_fmt2, format='%Y%m%d')\n",
    "df_sample\n",
    "# Jika penulisan bulan dengan menggunakan format singkatan 3 karakter nama bulan, seperti Apr untuk April, maka parameter format untuk pembacaannya dapat menggunakan %b\n",
    "df_sample['date03'] = pd.to_datetime(df_sample['date_fmt3'], format='%b.%d.%Y')\n",
    "df_sample\n",
    "# Terlihat dibawah, bahwa field date01, date02 dan date03 memiliki tipe data datetime64\n",
    "\n",
    "\n",
    "df_sample.dtypes\n",
    "### Mengekstrak Feature Pada Date\n",
    "df = df_sample[['date01', 'value']].copy()\n",
    "df.rename(columns={'date01': 'date_id'}, inplace=True)\n",
    "df.dtypes\n",
    "df['year'] = df['date_id'].dt.year\n",
    "df['month'] = df['date_id'].dt.month\n",
    "df['day'] = df['date_id'].dt.day\n",
    "df['querter-of-year'] = df['date_id'].dt.quarter\n",
    "df\n",
    "df['week-of-year'] = df['date_id'].dt.isocalendar().week\n",
    "df\n",
    "### Menghitung Selisih Antar Tanggal\n",
    "# Menghitung selisih hari biasanya digunakan ketika menghitung durasi dalam satuan hari.\n",
    "df['diff'] = df.date_id - pd.to_datetime('20200330', format='%Y%m%d')\n",
    "df\n",
    "# Untuk mengkonversikan menjadi numerik, dapat menngunakan atribut dt.days\n",
    "\n",
    "df['diff-in-days'] = df['diff'].dt.days\n",
    "df\n",
    "df.dtypes\n",
    "\n",
    "\n",
    "### Operasi Penambahan n Hari\n",
    "# Jika ingin melakukan penambahan hari, maka dapat dilakukan seperti kode dibawah ini\n",
    "\n",
    "df['seven-days-later'] = df.date_id + pd.Timedelta(days=7)\n",
    "df\n",
    "\n",
    "\n",
    "### Date Filtering\n",
    "# Secara umum fungsi-fungsi yang telah dijelaskan diatas dapat digunakan untuk memfilter data. Misalkan kita akan memfilter untuk menampilkan data-data antara tanggal 3 April hingga 7 April\n",
    "\n",
    "df[['date_id', 'value']] [(df.date_id > '04-03-2020') & (df.date_id < '04-07-2020')]\n",
    "\n",
    "# Perintah diatas memiliki 2 bagian:\n",
    "\n",
    "# 1. `[['date_id', 'value']]` \n",
    "# adalah nama field yang akan ditampilkan\n",
    "# 2. `[(df.date_id > '04-03-2020') & (df.date_id < '04-09-2020')]`\n",
    "# adalah filter yang digunakan, dalam hal ini adalah untuk menampilkan data-data antara tanggal 3 April hingga 9 April\n",
    "\n",
    "\n",
    "# Contoh lain adalah menampilkan data-data pada hari Rabu\n",
    "\n",
    "df[['date_id', 'value']] [(df.date_id.dt.strftime('%a') == 'Wed')]\n",
    "### Filtering menggunakan index\n",
    "# Jika akan melakukan banyak filtering menggunakan field date_id, akan lebih cepat jika field tanggal digunakan sebagai index, sehingga dapat memanfaatkan optimasi yang disediakan oleh Pandas.\n",
    "df = df.set_index(['date_id'])\n",
    "df\n",
    "df.loc['2020-04-05' : '2020-04-07']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
